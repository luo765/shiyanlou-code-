{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7e5535-5085-4c55-9b80-9913b729a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [' i am a boy?i am a boy ! i am a boy,i','god is a girl ','i love you']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed240177-c317-419a-938e-bbfdf6d298e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_english_text(text):\n",
    "    tokenized_text = []\n",
    "    for data in text:\n",
    "        tokenized_data = []\n",
    "        for s in data.split('.'):\n",
    "            for s1 in s.split('?'):\n",
    "                for s2 in s1.split('!'):\n",
    "                    for s3 in s2.split(','):\n",
    "                        tokenized_data.extend(\n",
    "                            s4 for s4 in s3.split(' ') if s4 != '')\n",
    "                        \n",
    "        tokenized_text.append(tokenized_data)\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e8c0f-ddfd-4f6f-8f64-0275ebd067c6",
   "metadata": {},
   "source": [
    "对英文语句实现. ? ! , 空格分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a14552b-3d3a-4812-bd32-5779cfa6e103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'am', 'a', 'boy', 'i', 'am', 'a', 'boy', 'i', 'am', 'a', 'boy', 'i'],\n",
       " ['god', 'is', 'a', 'girl'],\n",
       " ['i', 'love', 'you']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tokenize_english_text(a)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c4776-2692-461e-8489-6ad081796d97",
   "metadata": {},
   "source": [
    "中文分词方法：\n",
    "机械分词，又叫做基于规则的分词方法：这种分词方法按照一定的规则将待处理的字符串与一个词表词典中的词进行逐一匹配，若在词典中找到某个字符串，则切分，否则不切分。\n",
    "机械分词方法按照匹配规则的方式，又可以分为：正向最大匹配法，逆向最大匹配法和双向匹配法三种。\n",
    "正向最大匹配法（Maximum Match Method，MM 法）是指从左向右按最大原则与词典里面的词进行匹配。\n",
    "\n",
    "实现mm法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3749c378-0728-4ddc-93c2-9f5d8cc7d67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我们是共产主义的接班人'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '我们是共产主义的接班人'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d9dad4-37ad-42cd-8694-04bbe19e07fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = ('我们','是','共产主义','的','接班','人','你','我','社会','主义')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13093ac2-6bd5-4803-bb55-5dcff263dcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始最长词长度为 0\n",
    "max_len_word0 = 0\n",
    "for key in dic:\n",
    "    # 若当前词长度大于 max_len_word，则将 len(key)值赋值给 max_len_word\n",
    "    if len(key) > max_len_word0:\n",
    "        max_len_word0 = len(key)\n",
    "\n",
    "max_len_word0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d6e9bd-d0ce-4c4c-a0a7-2067930f62de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用 【 我们是共 】 进行匹配\n",
      "用 【 我们是 】 进行匹配\n",
      "用 【 我们 】 进行匹配\n",
      "【我们】 匹配成功，添加进 words 当中\n",
      "--------------------------------------------------\n",
      "用 【 是共 】 进行匹配\n",
      "用 【 是共产主 】 进行匹配\n",
      "用 【 是共产 】 进行匹配\n",
      "用 【 是共 】 进行匹配\n",
      "用 【 是 】 进行匹配\n",
      "【是】 匹配成功，添加进 words 当中\n",
      "--------------------------------------------------\n",
      "用 【 共产主义 】 进行匹配\n",
      "【共产主义】 匹配成功，添加进 words 当中\n",
      "--------------------------------------------------\n",
      "用 【 的接班人 】 进行匹配\n",
      "用 【 的接班 】 进行匹配\n",
      "用 【 的接 】 进行匹配\n",
      "用 【 的接班人 】 进行匹配\n",
      "用 【 的接班 】 进行匹配\n",
      "用 【 的接 】 进行匹配\n",
      "用 【 的 】 进行匹配\n",
      "【的】 匹配成功，添加进 words 当中\n",
      "--------------------------------------------------\n",
      "用 【 接班人 】 进行匹配\n",
      "用 【 接班人 】 进行匹配\n",
      "用 【 接班 】 进行匹配\n",
      "【接班】 匹配成功，添加进 words 当中\n",
      "--------------------------------------------------\n",
      "用 【 人 】 进行匹配\n",
      "【人】 匹配成功，添加进 words 当中\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "sent = text\n",
    "words = []   # 建立一个空数组来存放分词结果：\n",
    "max_len_word = max_len_word0\n",
    "# 判断 text 的长度是否大于 0，如果大于 0 则进行下面的循环\n",
    "while len(sent) > 0:\n",
    "    # 初始化想要取的字符串长度\n",
    "    # 按照最长词长度初始化\n",
    "    word_len = max_len_word\n",
    "    # 对每个字符串可能会有(max_len_word)次循环\n",
    "    for i in range(0, max_len_word):\n",
    "        # 令 word 等于 text 的前 word_len 个字符\n",
    "        word = sent[0:word_len]\n",
    "        # 为了便于观察过程，我们打印一下当前分割结果\n",
    "        print('用 【', word, '】 进行匹配')\n",
    "        # 判断 word 是否在词典 dic 当中\n",
    "        # 如果不在词典当中\n",
    "        if word not in dic:\n",
    "            # 则以 word_len - 1\n",
    "            word_len -= 1\n",
    "            # 清空 word\n",
    "            word = []\n",
    "        # 如果 word 在词典当中\n",
    "        else:\n",
    "            # 更新 text 串起始位置\n",
    "            sent = sent[word_len:]\n",
    "            # 为了方便观察过程，我们打印一下当前结果\n",
    "            print('【{}】 匹配成功，添加进 words 当中'.format(word))\n",
    "            print('-'*50)\n",
    "            # 把匹配成功的word添加进上面创建好的words当中\n",
    "            words.append(word)\n",
    "            # 清空word\n",
    "            word = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966aa00d-79e4-4984-8f9a-f3ffea830157",
   "metadata": {},
   "source": [
    "统计分词 分为\n",
    "语料统计方法 \n",
    "对多个语料进行频率分析，相连文本出现次数越多，越有可能组成一个词语。\n",
    "\n",
    "序列标注方法\n",
    "首先，规定每个字在一个词语当中有着 4 个不同的位置，词首 B，词中 M，词尾 E，单字成词 S。我们通过给一句话中的每个字标记上述的属性，最后通过标注来确定分词结果。\n",
    "例如：我今天要去实验室\n",
    "\n",
    "标注后得到：我/S 今/B 天/E 要/S 去/S 实/B 验/M 室/E\n",
    "\n",
    "标注序列是：S  B  E  S  S  B  M  E\n",
    "\n",
    "找到 S 、B 、 E 进行切词：S / B E / S / S / B M E /\n",
    "\n",
    "所以得到的切词结果是：我 / 今天 / 要 / 去 / 实验室\n",
    "\n",
    "两种结合的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6141532c-44c3-4440-9f90-2aa705007957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "string = '我来到北京清华大学'\n",
    "seg_list = jieba.cut(string, cut_all=True)#全模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1b81877-ca43-4a24-a4c6-ef5c21cf5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\luoso\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.313 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我|来到|北京|清华|清华大学|华大|大学'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b21b2fff-3f4c-43d3-ad35-ef86c2784a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我|来到|北京|清华大学'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_list = jieba.cut(string, cut_all=False)#精确模式\n",
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "901755b1-210f-4dec-a57b-5d4fa67636a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我|来到|北京|清华|华大|大学|清华大学'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_list = jieba.cut_for_search(string)#搜索引擎模式\n",
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b3a44-3345-48ca-9537-02ec9a1d7d26",
   "metadata": {},
   "source": [
    "使用jieba.load_userdic()导入自定义词典\n",
    "\n",
    "自定义词典的格式要求每一行一个词，有三个部分，词语，词频（词语出现的频率），词性（名词，动词……）。其中，词频和词性可省略。用户自定义词典可以直接用记事本创立即可，但是需要以 utf-8 编码模式保存。\n",
    "凶许 1 a\n",
    "脑斧 2 b\n",
    "福蝶 c\n",
    "小局 4 \n",
    "使用 add_word(word, freq=None, tag=None) 和 del_word(word) 可在程序中动态修改词典。\n",
    "使用 suggest_freq(segment, tune=True) 可调节单个词语的词频，使其能（或不能）被分出来。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22520a26-a86c-416a-9a7b-c067bb8b766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今天天气|不错'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '今天天气不错'\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15fe802-4166-49c0-b59a-7fd4b7c755e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今天|天气|不错'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.suggest_freq(('今天', '天气'), True)\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eaae733-1d3e-4bf0-b696-bf6c4efd2649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'今天|天气|不错'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.del_word('今天天气')\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cb277dd-91cd-462e-8903-07312b50ae75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台|中'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '台中'\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d1424fa-99db-499d-b8a0-9b2d4f836767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'台中'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.add_word('台中')#强调台中\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "'|'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2c7b969-b8e1-42b7-8bc1-17583c2fdd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '喜欢', '和', '你', '讨厌', '以及', '最', '不', '想要']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#简单过滤器\n",
    "string = '我喜欢的和你讨厌地以及最不想要得'\n",
    "stopwords = ('的','地','得')\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "\n",
    "a = []\n",
    "seg_list = jieba.cut(string, cut_all=False)\n",
    "for word in seg_list:\n",
    "    if word not in stopwords:\n",
    "        a.append(word)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc182d-5ef9-48a5-a2d6-d96b02946f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
